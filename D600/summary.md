# Course Summary
**D600: Statistical Data Mining** 

D600 delves into building and testing statistical models, specifically linear regression, logistic regression, and Principal Component Analysis (PCA). Learners will assess data sources, build sophisticated models, create visualizations, and deliver analytical results to support decision-making.
Course Objectives WGU outlines the following competencies as a part of this class:
- **Performs Regression Analysis:** The learner performs linear and logistic regressions to make recommendations based on the results.
- **Performs Dimensionality Reduction:** The learner performs principal component analysis to make recommendations based on the results.
# Course Materials 
This course utilizes Anaconda or R Studio as the IDE. Code and project progression are managed via GitLab repositories for all tasks. Panopto video recordings are a consistent submission requirement. Datasets like "Employee Turnover Dataset" and "D600 Task 1 Dataset 1 Housing Information.csv" are used.
Practical Assessment(s) Overview & Files
- **Task 1:** Linear Regression Analysis
    - **Description:** The goal is to build, test, and use a linear regression model to support decision-making. This includes proposing a research question and defining a data analysis goal. Data preparation involves identifying dependent and independent variables with justification, describing them with descriptive statistics (including a screenshot), and generating univariate and bivariate visualizations. The data is then split into training and test datasets. A regression model is created using the training data and optimized (e.g., forward stepwise selection, backward stepwise elimination, recursive selection). Key model parameters (adjusted R², R², F statistics, probability F statistics, coefficient estimates, p-value) or a summary screenshot are provided. The Mean Squared Error (MSE) of the optimized model on the training set is given, and predictions are run on the test dataset to assess accuracy based on MSE. The analysis summary includes listing and justifying chosen packages/libraries, discussing the optimization method and its justification, verifying assumptions, providing the regression equation and coefficient estimates, discussing model metrics (R², adjusted R², MSE comparison), and recommending a course of action.
    - **Output Files:** GitLab repository with committed code, documentation file for responses, training and test dataset files, and a Panopto video recording demonstrating code functionality and programming environment.
- **Task 2:** Logistic Regression Analysis
    - **Description:** This task focuses on building, testing, and using a logistic regression model. Similar to Task 1, it starts with a research question and a data analysis goal. Data preparation involves identifying and justifying dependent/independent variables, describing them with descriptive statistics (screenshot), and generating univariate/bivariate visualizations. Data is split into training and test datasets. A logistic regression model is created using the training data and optimized (similar methods as Task 1). Key model parameters (AIC, BIC, pseudo R², coefficient estimates, p-value) or a summary screenshot are provided. The confusion matrix and accuracy of the optimized model on the training set are given, and predictions are run on the test dataset to evaluate performance based on these metrics (screenshot of results). The summary includes listing/justifying packages/libraries, discussing optimization, summarizing at least four assumptions of logistic regression (with evidence of verification), providing the regression equation and coefficient estimates, discussing model metrics (test set accuracy, comparison of training/test accuracy, confusion matrix comparison), and recommending a course of action.
    - **Output Files:** GitLab repository with committed code, documentation file for responses, training and test dataset files, and a Panopto video recording demonstrating code functionality and programming environment.
- **Task 3:** Principal Component Analysis
    - **Description:** This task prepares a cleaned dataset for linear regression modeling using Principal Component Analysis (PCA). It uses the initial model code from Task 1, specifically for continuous variables. Learners propose a research question and define a goal (for linear regression). Reasons for using PCA are explained, including how it prepares data for regression (expected outcomes) and one assumption of PCA. Data preparation involves identifying continuous dataset variables, standardizing them (with a copy of the cleaned dataset), and describing them with descriptive statistics (screenshot). PCA is performed by determining the matrix of principal components, identifying the number of components to retain (using elbow rule or Kaiser rule, with scree plot screenshot), and identifying the variance of each retained component. PCA results are summarized. Data is split into training and test sets, containing only the identified principal components. A regression model is created using the training data and optimized. Model parameters or a summary screenshot (Adjusted R², R², F statistics, Probability F statistics, coefficient estimates, p-value) are provided. MSE for the training set is given, and predictions are run on the test set for accuracy based on MSE. The summary covers packages/libraries, optimization method/justification, assumption verification, regression equation/coefficient estimates, model metrics (R², adjusted R², MSE comparison), and a course of action.
    - **Output Files:** GitLab repository with committed code, documentation file for responses, training and test dataset files (with principal components), and a Panopto video recording demonstrating code functionality and programming environment.
